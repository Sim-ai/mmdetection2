{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "xml_root = \"./data/VOCdevkit/VOC2007/Annotations\"\n",
    "new_xml_root = \"./data/VOCdevkit/VOC2007/Annotations\"\n",
    "image_root = \"./data/VOCdevkit/VOC2007/JPEGImages\"\n",
    "\n",
    "xml_name_list = sorted(os.listdir(xml_root))\n",
    "\n",
    "\n",
    "def print_all_classes():\n",
    "    all_name_list = []\n",
    "    for xml_name in xml_name_list:\n",
    "        print(f\"{xml_name}\")\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            name = obj.find(\"name\").text\n",
    "            all_name_list.append(name)\n",
    "        print(all_name_list)\n",
    "\n",
    "\n",
    "def check_hw():\n",
    "    tranposed_name_lists = []\n",
    "    for xml_name in xml_name_list:\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        size = root.find(\"size\")\n",
    "        width = int(size.find(\"width\").text)\n",
    "        height = int(size.find(\"height\").text)\n",
    "        image_path = os.path.join(image_root, xml_name[:-4] + \".jpg\")\n",
    "        img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n",
    "        h, w, _ = img.shape\n",
    "        if height != h or width != w:\n",
    "            print(width, w, height, h)\n",
    "            print(f\"{xml_name}'s h, w is tranposed.\")\n",
    "            tranposed_name_lists.append(xml_name)\n",
    "    print(tranposed_name_lists)\n",
    "\n",
    "\n",
    "def check_bbox():\n",
    "    if not os.path.exists(new_xml_root):\n",
    "        os.makedirs(new_xml_root)\n",
    "\n",
    "    for xml_name in xml_name_list:\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            bnd_box = obj.find(\"bndbox\")\n",
    "            bbox = [\n",
    "                int(float(bnd_box.find(\"xmin\").text)),\n",
    "                int(float(bnd_box.find(\"ymin\").text)),\n",
    "                int(float(bnd_box.find(\"xmax\").text)),\n",
    "                int(float(bnd_box.find(\"ymax\").text)),\n",
    "            ]\n",
    "            image_path = os.path.join(image_root, xml_name[:-4] + \".jpg\")\n",
    "            img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n",
    "            h, w, _ = img.shape\n",
    "            \n",
    "            if bbox[0] == 0:\n",
    "                bnd_box.find(\"xmin\").text = str(1)\n",
    "                bbox[0] == 1\n",
    "            elif bbox[1] == 0:\n",
    "                bnd_box.find(\"ymin\").text = str(1)\n",
    "                bbox[1] == 1\n",
    "            elif bbox[2] == w:\n",
    "                bnd_box.find(\"xmax\").text = str(w-1)\n",
    "                bbox[2] == w-1\n",
    "            elif bbox[3] == h:\n",
    "                bnd_box.find(\"ymax\").text = str(h-1)\n",
    "                bbox[3] == h-1\n",
    "\n",
    "                \n",
    "            if bbox[0] >= bbox[2] or bbox[1] >= bbox[3]:\n",
    "                print(\"bbox[0] >= bbox[2] or bbox[1] >= bbox[3]\", bbox, xml_name)\n",
    "                # bboxes = np.array([bbox])\n",
    "                # mmcv.imshow_det_bboxes(img, bboxes, labels=np.array([\"h\"]))\n",
    "                # bbox_min_ge_max_name_lists.append(xml_name)\n",
    "                root.remove(obj)\n",
    "            elif bbox[3] > h or bbox[2] > w:\n",
    "                bnd_box.find(\"xmax\").text = str(min(w, bbox[2]))\n",
    "                bnd_box.find(\"ymax\").text = str(min(h, bbox[3]))\n",
    "                print(\"bbox[3] > h or bbox[2] > w\", bbox, h, w, xml_name)\n",
    "                # bboxes = np.array([bbox])\n",
    "                # mmcv.imshow_det_bboxes(img, bboxes, labels=np.array([\"h\"]))\n",
    "                # bbox_max_border_name_lists.append(xml_name)\n",
    "\n",
    "        tree.write(os.path.join(new_xml_root, xml_name))\n",
    "\n",
    "check_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area to small: 0, 1 (10)_0.xml\n",
      "Area to small: 0, 1 (19)_3.xml\n",
      "Area to small: 0, 5 (4)_1.xml\n",
      "Area to small: 0, 6 (6)_7.xml\n",
      "Area to small: 4, 6_3.xml\n",
      "Area to small: 0, W0003_0001_7.xml\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "xml_root = \"./data/VOCdevkit/VOC2007/Annotations\"\n",
    "new_xml_root = \"./data/VOCdevkit/VOC2007/Annotations\"\n",
    "image_root = \"./data/VOCdevkit/VOC2007/JPEGImages\"\n",
    "\n",
    "xml_name_list = sorted(os.listdir(xml_root))\n",
    "\n",
    "\n",
    "def print_all_classes():\n",
    "    all_name_list = []\n",
    "    for xml_name in xml_name_list:\n",
    "        print(f\"{xml_name}\")\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            name = obj.find(\"name\").text\n",
    "            all_name_list.append(name)\n",
    "        print(all_name_list)\n",
    "\n",
    "\n",
    "def check_hw():\n",
    "    tranposed_name_lists = []\n",
    "    for xml_name in xml_name_list:\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        size = root.find(\"size\")\n",
    "        width = int(size.find(\"width\").text)\n",
    "        height = int(size.find(\"height\").text)\n",
    "        image_path = os.path.join(image_root, xml_name[:-4] + \".jpg\")\n",
    "        img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n",
    "        h, w, _ = img.shape\n",
    "        if height != h or width != w:\n",
    "            print(width, w, height, h)\n",
    "            print(f\"{xml_name}'s h, w is tranposed.\")\n",
    "            tranposed_name_lists.append(xml_name)\n",
    "    print(tranposed_name_lists)\n",
    "\n",
    "\n",
    "def check_bbox():\n",
    "    if not os.path.exists(new_xml_root):\n",
    "        os.makedirs(new_xml_root)\n",
    "\n",
    "    for xml_name in xml_name_list:\n",
    "        xml_path = os.path.join(xml_root, xml_name)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for obj in root.findall(\"object\"):\n",
    "            bnd_box = obj.find(\"bndbox\")\n",
    "            bbox = [\n",
    "                int(float(bnd_box.find(\"xmin\").text)),\n",
    "                int(float(bnd_box.find(\"ymin\").text)),\n",
    "                int(float(bnd_box.find(\"xmax\").text)),\n",
    "                int(float(bnd_box.find(\"ymax\").text)),\n",
    "            ]\n",
    "            image_path = os.path.join(image_root, xml_name[:-4] + \".jpg\")\n",
    "            img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)\n",
    "            h, w, _ = img.shape\n",
    "            \n",
    "            area = (bbox[3] - bbox[1]) * (bbox[2] - bbox[0])\n",
    "            if area <= 4:\n",
    "                print(f\"Area to small: {area}, {xml_name}\")\n",
    "\n",
    "        tree.write(os.path.join(new_xml_root, xml_name))\n",
    "\n",
    "check_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cqupt1811/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import os\n",
    "import mmcv\n",
    "import glob\n",
    "import torch\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = 'configs/hrnet/cascade_rcnn_hrnetv2p_w32_20e_coco.py'\n",
    "checkpoint_file = 'work_dirs/cascade_rcnn_hrnetv2p_w32_20e_coco/latest.pth'\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "# model = init_detector(config_file, checkpoint_file, device='cpu')\n",
    "\n",
    "h_slice = 3\n",
    "w_slice = 3\n",
    "dir_root = \"data/images\"\n",
    "\n",
    "\n",
    "result_sub_image = []\n",
    "os.makedirs(os.path.join(dir_root, \"results\"), exist_ok=True)\n",
    "for img in glob.glob(os.path.join(dir_root, \"*.jpg\")):\n",
    "    # 切割\n",
    "    image = mmcv.imread(img)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    _h = h + 1 - h % h_slice\n",
    "    _w = w + 1 - w % w_slice\n",
    "    h_grid = np.arange(0, _h, h // h_slice)\n",
    "    w_grid = np.arange(0, _w, w // w_slice)\n",
    "\n",
    "    lt = []\n",
    "    rb = []\n",
    "    coor_slice = list(product(h_grid, w_grid))\n",
    "\n",
    "    for r in range(h_slice):\n",
    "        for i in range(r * (w_slice + 1), r * (w_slice + 1) + w_slice):\n",
    "            lt.append(coor_slice[i])\n",
    "            rb.append(coor_slice[i + w_slice + 2])\n",
    "\n",
    "    for _i, (_lt, _rb) in enumerate(list(zip(lt, rb))):\n",
    "        sub_lty, sub_ltx = _lt\n",
    "        sub_rby, sub_rbx = _rb\n",
    "\n",
    "        sub_image = image[sub_lty:sub_rby, sub_ltx:sub_rbx, :]\n",
    "\n",
    "        sub_result = inference_detector(model, sub_image)\n",
    "        ## TODO: 此处做了额外的一步保存工作\n",
    "        model.show_result(sub_image, sub_result, out_file=os.path.join(os.path.dirname(img), 'results', 'tmp.jpg'))\n",
    "#         tmp_image = ToTensor()(Image.open(os.path.join(os.path.dirname(img), 'results', 'tmp.jpg')))\n",
    "        tmp_image = mmcv.imread(os.path.join(os.path.dirname(img), 'results', 'tmp.jpg'))\n",
    "        result_sub_image.append(tmp_image)\n",
    "        \n",
    "    ## 拼湊子圖\n",
    "    h, w, _ = result_sub_image[0].shape\n",
    "    TARGET_HEIGHT = h * h_slice\n",
    "    TARGET_WIDTH = w * w_slice\n",
    "#     new_image = torch.zeros((_, TARGET_HEIGHT, TARGET_WIDTH))\n",
    "    new_image = np.zeros((TARGET_HEIGHT, TARGET_WIDTH, _))\n",
    "\n",
    "    ## 拼接\n",
    "    for _idx in range(0, h_slice * w_slice):\n",
    "        image = result_sub_image[_idx]\n",
    "        new_image[(_idx//w_slice) * h: (_idx//w_slice + 1) * h, (_idx%w_slice) * w: (_idx%w_slice + 1) * w, :] = np.copy(image)\n",
    "\n",
    "#     new_image = transforms.ToPILImage()(new_image)\n",
    "#     new_image.save(os.path.join(\"data/images/results/\", os.path.splitext(os.path.basename(img))[0]+\"_result.jpg\"))\n",
    "    mmcv.imwrite(new_image, os.path.join(os.path.join(dir_root, \"results\"), os.path.splitext(os.path.basename(img))[0]+\"_result.jpg\"))\n",
    "    result_sub_image.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-52afc83fe3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/images/W0003_0006_0.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mmdetection/mmdet/apis/inference.py\u001b[0m in \u001b[0;36minference_detector\u001b[0;34m(model, img)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;31m# build the data pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mtest_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mmdetection/mmdet/datasets/pipelines/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mmdetection/mmdet/datasets/pipelines/loading.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'img'"
     ]
    }
   ],
   "source": [
    "## test\n",
    "img = \"data/images/W0003_0006_0.jpg\"\n",
    "result = inference_detector(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10588235],\n",
       "        [0.14901961],\n",
       "        [0.18431373],\n",
       "        ...,\n",
       "        [0.13725491],\n",
       "        [0.14117648],\n",
       "        [0.14117648]],\n",
       "\n",
       "       [[0.11764706],\n",
       "        [0.16078432],\n",
       "        [0.2       ],\n",
       "        ...,\n",
       "        [0.12941177],\n",
       "        [0.13333334],\n",
       "        [0.13333334]],\n",
       "\n",
       "       [[0.1254902 ],\n",
       "        [0.17254902],\n",
       "        [0.21568628],\n",
       "        ...,\n",
       "        [0.13333334],\n",
       "        [0.13333334],\n",
       "        [0.13333334]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.3882353 ],\n",
       "        [0.42352942],\n",
       "        ...,\n",
       "        [0.77254903],\n",
       "        [0.77254903],\n",
       "        [0.7529412 ]],\n",
       "\n",
       "       [[0.3882353 ],\n",
       "        [0.38431373],\n",
       "        [0.4117647 ],\n",
       "        ...,\n",
       "        [0.7764706 ],\n",
       "        [0.77254903],\n",
       "        [0.7490196 ]],\n",
       "\n",
       "       [[0.37254903],\n",
       "        [0.39607844],\n",
       "        [0.42352942],\n",
       "        ...,\n",
       "        [0.75686276],\n",
       "        [0.7529412 ],\n",
       "        [0.74509805]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
